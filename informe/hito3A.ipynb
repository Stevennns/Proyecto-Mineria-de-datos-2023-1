{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clasificador"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El objetivo es entrenar un clasificador que sea capaz de distinguir entre los distintos tipos de informacion humanitaria presente en los tweets. Dentro de las categorías que componen \"text_human\" están: missing_or_found_people, vehicle_damage, affected_individuals, injured_or_dead_people, infrastructure_and_utility_damage, rescue_volunteering_or_donation_effort, not_humanitarian y other_relevant_information.\n",
    "Como algunas de estás categorías tienen poca frecuencia se decide juntar las categorías que traten temas parecidos en una sola. En consecuencia, se crea una nueva categoría de \"Perdidas\".\n",
    "\n",
    "Aparte de esto se decide realizar el entrenamiento del clasificador solamente sobre los tweets que tengan infromación humanitario, es decir, los tweets marcados como \"not_humanitarian\" no se tendran en cuenta para la clasificacion.\n",
    "\n",
    "El clasificador será entrenado de forma exclusiva sobre el texto de los tweets, por lo tanto es necesario realizar un embedding de los tweets para que el texto pueda ser procesado por un modelo. Por ende, hay que elegir una forma de vectorizar el texto de los tweets. Se decidió usar vectores preentrenados para hacer el embedding y se usaron los vectores de 200 dimensiones de GloVe.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Para responder a esta pregunta, se requiere realizar un análisis del texto de los tweets utilizando técnicas de procesamiento de lenguaje natural (NLP).<br/>\n",
    "\n",
    "El clasificador será entrenado de forma exclusiva sobre el texto de los tweets, por lo tanto es necesario realizar un embedding de los tweets para que el texto pueda ser procesado por un modelo. Inicialmente, se planteó la utilización de la técnica Word2Vec para realizar el embedding del texto de los tweets. Sin embargo, después de observar algunos resultados preliminares, se decidió cambiar a la utilización del modelo GloVe, el cual cuenta con vectores preprocesados de dimensión 200. Esto mejorará los resultados y la velocidad de procesamiento. Además, se utilizarán las palabras más frecuentes del dataset, en este caso, los nombres de los desastres y sus ubicaciones, como stopwords durante el preprocesamiento para el entrenamiento del clasificador.<br/>\n",
    "\n",
    "A continuación, se separarán los conjuntos de entrenamiento y prueba en un 80\\% y 20\\% de los datos, respectivamente. Posteriormente, se generarán los vectores y los textos de entrenamiento y prueba. Finalmente, se calculará el promedio de la representación vectorial de cada palabra en un tweet.<br/>\n",
    "Con todo este procesamiento, se utilizarán diferentes clasificadores y se compararán sus resultados. En particular, se planea utilizar los siguientes:<br/>\n",
    "\n",
    "\n",
    "Como algunas de estás categorías tienen poca frecuencia se decide juntar las categorías que traten temas parecidos en una sola. \n",
    "\n",
    "Aparte de esto se decide realizar el entrenamiento del clasificador solamente sobre los tweets que tengan infromación humanitario, es decir, los tweets marcados como \"not_humanitarian\" no se tendran en cuenta para la clasificacion.\n",
    "\n",
    "El objetivo es entrenar un clasificador que sea capaz de distinguir entre los distintos tipos de informacion humanitaria presente en los tweets. Dentro de las categorías que componen \"text_human\" están: missing_or_found_people, vehicle_damage, affected_individuals, injured_or_dead_people, infrastructure_and_utility_damage, rescue_volunteering_or_donation_effort, not_humanitarian y other_relevant_information. Por lo anterior, se considerará realizar un rebalanceo de las clases, ya que las últimas 4 etiquetas del gráfico presentan una frecuencia considerablemente menor que las demás. Se propone agrupar estas 4 etiquetas en una única columna para mitigar este desequilibrio.En consecuencia, se crea una nueva categoría de \"Pérdidas\". \n",
    "También se evaluarán qué parámetros utilizar para entrenar el clasificador, además del texto.<br/>\n",
    "Para evaluar la efectividad de los clasificadores, se utilizarán diversas métricas como la exactitud (accuracy), la precisión (precision), la recuperación (recall) y la puntuación F1 (F1 score)."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
