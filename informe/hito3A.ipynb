{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clasificador"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Para responder a esta pregunta, se requiere realizar un análisis del texto de los tweets utilizando técnicas de procesamiento de lenguaje natural (NLP).<br/>\n",
    "\n",
    "El clasificador será entrenado de forma exclusiva sobre el texto de los tweets, por lo tanto es necesario realizar un embedding de los tweets para que el texto pueda ser procesado por un modelo. Inicialmente, se planteó la utilización de la técnica Word2Vec para realizar el embedding del texto de los tweets. Sin embargo, después de observar algunos resultados preliminares, se decidió cambiar a la utilización del modelo GloVe, el cual cuenta con vectores preprocesados de dimensión 200. Esto mejorará los resultados y la velocidad de procesamiento. Además, se utilizarán las palabras más frecuentes del dataset, en este caso, los nombres de los desastres y sus ubicaciones, como stopwords durante el preprocesamiento para el entrenamiento del clasificador.<br/>\n",
    "\n",
    "Aparte de esto se decide realizar el entrenamiento del clasificador solamente sobre los tweets que tengan infromación humanitario, es decir, los tweets marcados como \"not_humanitarian\" no se tendran en cuenta para la clasificacion.\n",
    "\n",
    "A continuación, se separarán los conjuntos de entrenamiento y prueba en un 80\\% y 20\\% de los datos, respectivamente. Posteriormente, se generarán los vectores y los textos de entrenamiento y prueba. Finalmente, se calculará el promedio de la representación vectorial de cada palabra en un tweet.<br/>\n",
    "Con todo este procesamiento, se utilizarán diferentes clasificadores y se compararán sus resultados. En particular, se planea utilizar los siguientes:<br/>\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "El objetivo es entrenar un clasificador que sea capaz de distinguir entre los distintos tipos de informacion humanitaria presente en los tweets. Dentro de las categorías que componen \"text_human\" están: missing_or_found_people, vehicle_damage, affected_individuals, injured_or_dead_people, infrastructure_and_utility_damage, rescue_volunteering_or_donation_effort, not_humanitarian y other_relevant_information. Por lo anterior, se considerará realizar un rebalanceo de las clases, ya que las últimas 4 etiquetas del gráfico presentan una frecuencia considerablemente menor que las demás. Se propone agrupar estas 4 etiquetas en una única columna para mitigar este desequilibrio.En consecuencia, se crea una nueva categoría de \"Pérdidas\". \n",
    "También se evaluarán qué parámetros utilizar para entrenar el clasificador, además del texto.<br/>\n",
    "Para evaluar la efectividad de los clasificadores, se utilizarán diversas métricas como la exactitud (accuracy), la precisión (precision), la recuperación (recall) y la puntuación F1 (F1 score)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelos\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se probaron 4 modelos para probar el clasificador:\n",
    "\n",
    "- Linear SVC\n",
    "- Decision Tree\n",
    "- Ranodm Forest\n",
    "- Naive Bayes Gaussian \n",
    "\n",
    "\n",
    "Se clasificó entre las categorias human_and_material_losses, other_relevant_information, rescue_volunteering_or_donation_effort y not_humanitarian. Dando los siguientes resultados:\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>\n",
    "<table>\n",
    "  <tr>\n",
    "    <th>Modelo</th>\n",
    "    <th>Accuracy</th>\n",
    "    <th>Precision</th>\n",
    "    <th>Recall</th>\n",
    "    <th>F1 Score</th>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>Linear SVC</td>\n",
    "    <td>0.628</td>\n",
    "    <td>0.635</td>\n",
    "    <td>0.612</td>\n",
    "    <td>0.619</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>Decision tree</td>\n",
    "    <td>0.422</td>\n",
    "    <td>0.402</td>\n",
    "    <td>0.401</td>\n",
    "    <td>0.402</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>Random Forest</td>\n",
    "    <td>0.586</td>\n",
    "    <td>0.637</td>\n",
    "    <td>0.533</td>\n",
    "    <td>0.548</td>\n",
    "  </tr>\n",
    "   <tr>\n",
    "    <td>Naive Bayes Gaussian</td>\n",
    "    <td>0.596</td>\n",
    "    <td>0.587</td>\n",
    "    <td>0.602</td>\n",
    "    <td>0.593</td>\n",
    "  </tr>\n",
    "</table>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "También se hizo un experimento quitando la categoría not humanitarian de la clasificación, de esta forma el clasificador sólo clasifica dentro de un conjunto de tweets con información humanitaria. Sus scores fueron un poco mejores que antes, para Linear SVC estos fueron los resultados:\n",
    "\n",
    "- Accuracy: 0.743\n",
    "- Decision tree: 0.728\n",
    "- Random Forest: 0.694\n",
    "- Naive Bayes Gaussian: 0.698\n",
    "\n",
    "Se pude ver que Linear SVC fue el modelo con mejor rendimiento de los 4, mientras que Decision tree fue el peor.\n",
    "En conclusión vemos que es posible entrenar el clasificador para que pueda clasificar los tweets en cada categoria con buenos resutados. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
