{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e9e97451",
   "metadata": {},
   "source": [
    "### <center>CC5205 - Minería de Datos</center>\n",
    "# <center>Multimodal Crisis Dataset - Hito 3</center>\n",
    "##### <center>Grupo 1</center>\n",
    "\n",
    "<center>Integrantes: Jorge Araya, Jesús Cáceres, Agustín Cortés, Stevens Egli, Jessica Gajardo.</center>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7b9e3499",
   "metadata": {},
   "source": [
    "Este trabajo se centra en la exploración del conjunto de datos de [Crisisnlp](https://crisisnlp.qcri.org/), específicamente el recurso número 5, constituido de tweets e imágenes relacionadas a siete grandes desastres naturales ocurridos en el año 2017:\n",
    "* Terremoto de México\n",
    "* Terremoto de Iraq\n",
    "* Huracán María\n",
    "* Huracán Irma\n",
    "* Huracán Harvey\n",
    "* Incendio de California\n",
    "* Inundación de Srilanka\n",
    "\n",
    "La motivación principal del grupo fue explorar los datos, intentando encontrar alguna tendencia de las características de los tweets relacionados a estos desastres en cuanto su magnitud y su difusión. Surgió el interés de verificar si es posible conseguir una escala para los desastres en función de las interacciones sociales alrededor de estos, específicamente las realizadas a través de la plataforma de twitter."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7c3ed05e",
   "metadata": {},
   "source": [
    "### Características del Dataset"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "74de5338",
   "metadata": {},
   "source": [
    "El dataset obtenido del sitio web contiene tres carpetas: **annotations**, **json** y **data_image**. \n",
    "La carpeta *annotations* corresponde a archivos *.tsv* con información medida, verificada y etiquetada manualmente acerca de cada tweet.<br/>\n",
    "En *data_image* se encuentran las rutas a las fotos extraídas de los tweet. Dado que el análisis de imágenes se encuentra fuera del enfoque principal de este primer hito, se decidió no trabajar con esta carpeta. Por último, la carpeta *json* contiene archivos *.json* con información completa y sin filtro de los tweets.<br/>\n",
    "Este contenido corresponde a un sampleo ya manipulado por los académicos que dejaron disponible el dataset. Por lo que la cantidad de registros de los que se dispone es mucho menor a los registros iniciales descritos en el sitio web."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c5991c96",
   "metadata": {},
   "source": [
    "### Exploración de los datos"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "df025d94",
   "metadata": {},
   "source": [
    "Al estudiar el contenido de los archivos *json*, se observó que cada registro de tweet tiene una gran cantidad de información anidada y difícil de analizar con algoritmos convencionales de exploración. Debido a esto, se decidió extraer manualmente las siguientes columnas, las cuales fueron consideradas más útiles para responder a la motivación de este hito:\n",
    "\n",
    "<style>\n",
    "  .list-columns1 {\n",
    "    display: flex;\n",
    "    flex-wrap: wrap;\n",
    "    justify-content: space-between;\n",
    "    align-items: flex-start;\n",
    "    list-style: none;\n",
    "    padding: 0;\n",
    "    margin: 0;\n",
    "  }\n",
    "\n",
    "  .list-columns1 li {\n",
    "    width: 50%;\n",
    "    margin-bottom: 20px;\n",
    "  }\n",
    "</style>\n",
    "\n",
    "<ul class=\"list-columns1\">\n",
    "  <li><b>quote_count:</b> Cantidad de citas a un tweet.</li>\n",
    "  <li><b>possibly_sensitive:</b> Booleano, verdadero si el tweet es sensible.</li>\n",
    "  <li><b>lang:</b> Idioma del texto.</li>\n",
    "  <li><b>id:</b> Identificador único de un tweet.</li>\n",
    "  <li><b>created_at:</b> Fecha de creación del tweet.</li>\n",
    "  <li><b>favorite_count:</b> Cantidad de favoritos.</li>\n",
    "  <li><b>text:</b> Texto del tweet.</li>\n",
    "  <li><b>reply_count:</b> Cantidad de respuestas.</li>\n",
    "  <li><b>entities/hashtags:</b> Lista de hashtags que tiene el tweet.</li>\n",
    "  <li><b>entities/urls:</b> Booleano, verdadero si hay al menos una URL el tweet.</li>\n",
    "  <li><b>is_quote_status:</b> Booleano, verdadero si el tweet es una cita.</li>\n",
    "  <li><b>retweet_count:</b> Cantidad de retweets.</li>\n",
    "  <li><b>user/Location:</b> Localización del usuario que escribió el tweet.</li>\n",
    "</ul>\n",
    "\n",
    "Adicionalmente, mediante el análisis del dataframe, se logra apreciar que todas las columnas *lang* del dataframe tenían el valor *en* (inglés), por lo que se terminó descartando el uso del *lang* para el análisis. En los archivos .tsv de los desastres, los registros tienen las siguientes características de interés:\n",
    "* *text_info*: Si el tweet es informativo o no (clasificación binaria)\n",
    "* *text_info_conf*: La confiabilidad del aspecto informativo (certeza de la clasificación dada)\n",
    "* *text_human*: Qué aspecto humanitario aborda el tweet (8 clases posibles)\n",
    "* *text_human_conf*: La confiabilidad del aspecto humanitario (certeza de la clasificación dada)\n",
    "\n",
    "Estas columnas se extraen del .tsv y se mezclan con las columnas seleccionadas del .json por cada desastre natural, identificando los tweets por su ID. Con esto se construyeron los dataframes utilizados en el estudio de los desastres.Adicionalmente se agregaron las siguientes columnas:\n",
    "* *json_name*: String, corresponde al nombre del desastre al que pertenece el tweet.\n",
    "* *has_image*: Booleano, indica si el tweet posee al menos una imagen.\n",
    "* *magnitud*: Número, valor correspondiente a la magnitud del desastre natural al que pertenece el tweet."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "68499baf",
   "metadata": {},
   "source": [
    "### Estadísticas y visualizaciones"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ca870955",
   "metadata": {},
   "source": [
    "#### Estadísticas de resumen"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "17c00a13",
   "metadata": {},
   "source": [
    "Se calcularon estadísticas de resumen para todos los desastres, la siguiente tabla muestra las características de resumen para un dataframe que combina los registros de todos los desastres. \n",
    "<table>\n",
    "  <tr>\n",
    "    <th></th>\n",
    "    <th>favorite_count</th>\n",
    "    <th>retweet_count</th>\n",
    "    <th>reply_count</th>\n",
    "    <th>quote_count</th>\n",
    "    <th>text_info_conf</th>\n",
    "    <th>text_human_conf</th>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>count</td>\n",
    "    <td>15224.000000</td>\n",
    "    <td>15224.000000</td>\n",
    "    <td>14911.000000</td>\n",
    "    <td>14912.000000</td>\n",
    "    <td>13146.000000</td>\n",
    "    <td>13146.000000</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>mean</td>\n",
    "    <td>40.848726</td>\n",
    "    <td>21.024961</td>\n",
    "    <td>1.591577</td>\n",
    "    <td>2.521929</td>\n",
    "    <td>0.791305</td>\n",
    "    <td>0.791305</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>std</td>\n",
    "    <td>860.529477</td>\n",
    "    <td>472.872880</td>\n",
    "    <td>37.779951</td>\n",
    "    <td>61.157195</td>\n",
    "    <td>0.201238</td>\n",
    "    <td>0.201238</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>min</td>\n",
    "    <td>0.000000</td>\n",
    "    <td>0.000000</td>\n",
    "    <td>0.000000</td>\n",
    "    <td>0.000000</td>\n",
    "    <td>0.258100</td>\n",
    "    <td>0.258100</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>25%</td>\n",
    "    <td>0.000000</td>\n",
    "    <td>0.000000</td>\n",
    "    <td>0.000000</td>\n",
    "    <td>0.000000</td>\n",
    "    <td>0.659600</td>\n",
    "    <td>0.659600</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>50%</td>\n",
    "    <td>0.000000</td>\n",
    "    <td>0.000000</td>\n",
    "    <td>0.000000</td>\n",
    "    <td>0.000000</td>\n",
    "    <td>0.698450</td>\n",
    "    <td>0.698450</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>75%</td>\n",
    "    <td>0.000000</td>\n",
    "    <td>0.000000</td>\n",
    "    <td>0.000000</td>\n",
    "    <td>0.000000</td>\n",
    "    <td>1.000000</td>\n",
    "    <td>1.000000</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>max</td>\n",
    "    <td>51726.000000</td>\n",
    "    <td>36840.000000</td>\n",
    "    <td>3797.000000</td>\n",
    "    <td>4010.000000</td>\n",
    "    <td>1.000000</td>\n",
    "    <td>1.000000</td>\n",
    "  </tr>\n",
    "</table>\n",
    "\n",
    "Se puede ver que las interacciones de los tweets son casi inexistentes en la mayoria de registros. Valores distintos a 0 recién empiezan a aparecer por sobre el tercer cuartil de los registros.\n",
    "Las estadísticas para cada desastre individual se pueden obtener replicando los códigos del anexo."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "886d695e",
   "metadata": {},
   "source": [
    "#### Visualizaciones"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "501545da",
   "metadata": {},
   "source": [
    "##### Histogramas"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7fffb048",
   "metadata": {},
   "source": [
    "##### Correlaciones"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "16d54913",
   "metadata": {},
   "source": [
    "La siguiente tabla muestra las correlaciones entre las columnas cuantitativas del dataframe con todos los desastres. Las columnas *text_info* y *text_human* fueron mapeadas de string a enteros para poder realizar esta correlación."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f0178d10",
   "metadata": {},
   "source": [
    "<center>\n",
    "<table>\n",
    "  <tr>\n",
    "    <th></th>\n",
    "    <th>favorite_count</th>\n",
    "    <th>retweet_count</th>\n",
    "    <th>possibly_sensitive</th>\n",
    "    <th>reply_count</th>\n",
    "    <th>quote_count</th>\n",
    "    <th>text_info</th>\n",
    "    <th>text_human</th>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>favorite_count</td>\n",
    "    <td>1.000000</td>\n",
    "    <td>0.919928</td>\n",
    "    <td>-0.000964</td>\n",
    "    <td>0.709378</td>\n",
    "    <td>0.553119</td>\n",
    "    <td>-0.086793</td>\n",
    "    <td>-0.094353</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>retweet_count</td>\n",
    "    <td>0.919928</td>\n",
    "    <td>1.000000</td>\n",
    "    <td>-0.001934</td>\n",
    "    <td>0.606207</td>\n",
    "    <td>0.616322</td>\n",
    "    <td>-0.081295</td>\n",
    "    <td>-0.088376</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>possibly_sensitive</td>\n",
    "    <td>-0.000964</td>\n",
    "    <td>-0.001934</td>\n",
    "    <td>1.000000</td>\n",
    "    <td>-0.002455</td>\n",
    "    <td>-0.001630</td>\n",
    "    <td>0.005151</td>\n",
    "    <td>-0.002635</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>reply_count</td>\n",
    "    <td>0.709378</td>\n",
    "    <td>0.606207</td>\n",
    "    <td>-0.002455</td>\n",
    "    <td>1.000000</td>\n",
    "    <td>0.345626</td>\n",
    "    <td>-0.077976</td>\n",
    "    <td>-0.085081</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>quote_count</td>\n",
    "    <td>0.553119</td>\n",
    "    <td>0.616322</td>\n",
    "    <td>-0.001630</td>\n",
    "    <td>0.345626</td>\n",
    "    <td>1.000000</td>\n",
    "    <td>-0.076328</td>\n",
    "    <td>-0.083285</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>text_info</td>\n",
    "    <td>-0.086793</td>\n",
    "    <td>-0.081295</td>\n",
    "    <td>0.005151</td>\n",
    "    <td>-0.077976</td>\n",
    "    <td>-0.076328</td>\n",
    "    <td>1.000000</td>\n",
    "    <td>0.509454</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>text_human</td>\n",
    "    <td>-0.094353</td>\n",
    "    <td>-0.088376</td>\n",
    "    <td>-0.002635</td>\n",
    "    <td>-0.085081</td>\n",
    "    <td>-0.083285</td>\n",
    "    <td>0.509454</td>\n",
    "    <td>1.000000</td>\n",
    "  </tr>\n",
    "</table>\n",
    "</center>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3b678ad8",
   "metadata": {},
   "source": [
    "Se puede ver la conexión existente entre las interacciones de los usuarios, aquellos tweets con muchos retweets tienden a tener muchas respuestas o ser citados más a menudo. Sin embargo no se aprecia una relación entre estos valores y la clasificación asignada al atributo humanitario o de información de los tweets.\n",
    "Se presume que estas últimas columnas dependen mucho más del contenido del texto y las imágenes que se dejaron aparte para este hito. Se evaluará su utilización para las siguientes entregas."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "442947d5",
   "metadata": {},
   "source": [
    "##### Clasificación de tweet"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "71872914",
   "metadata": {},
   "source": [
    "Se realizó un gráfico de barras con el dataframe que contiene todos los registros de desastres para el atributo *text_human*, el cual indica la clasificación del texto del tweet. Los académicos que asignaron estas etiquetas utilizaron un algoritmo que, además de clasificar los tweets, les informaba que tan certera era esta clasificación. Para este gráfico se consideraron todos aquellos tweets que poseen confiabilidad del 100% de su clasificación *text_human*.\n",
    "\n",
    "<center>\n",
    "<div>\n",
    "    <img src=\"images/text_human_graph.png\" width=\"400\"/>\n",
    "    <figcaption>Fig d.1 - Clasificación humanitaria de tweets</figcaption>\n",
    "</div>\n",
    "</center>\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4cd4612a",
   "metadata": {},
   "source": [
    "### Mejoras del hito I"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "43db3958",
   "metadata": {},
   "source": [
    "##### Conteo de palabras"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a377492a",
   "metadata": {},
   "source": [
    "Para iniciar el proceso, se tomó la decisión de trabajar con todos los desastres en conjunto y se agregó una columna que indica a qué desastre pertenece cada tweet. Además, se incluyeron dos nuevas columnas en el conjunto de datos: \"TDD\", que indica los días transcurridos desde el inicio de la catástrofe, y \"has_image\", un valor booleano que indica si el tweet contiene una imagen. También se eliminaron todos los tweets que no pertenecieran al año 2017. A continuación, se realizaron nuevas visualizaciones para mejorar la exploración de datos. Los gráficos muestran las palabras más frecuentes en los tweets:\n",
    "\n",
    "<center>\n",
    "<table><tr>\n",
    "<td>\n",
    "<div>\n",
    "    <img src=\"images/palabras_frecuentes1.png\" width=\"460\"/>\n",
    "    <figcaption>Fig d.3 - Gráfico de nube: palabras más frecuentes en los tweets</figcaption>\n",
    "</div>\n",
    "</td>\n",
    "<td>\n",
    "<div>\n",
    "    <img src=\"images/palabras_frecuentes2.png\" width=\"600\"/>\n",
    "    <figcaption>Fig d.4 - Gráfico de barras: palabras más frecuentes en los tweets</figcaption>\n",
    "</div>\n",
    "</td>\n",
    "</tr></table>\n",
    "</center>\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6c166e91",
   "metadata": {},
   "source": [
    "##### Cantidad de tweets"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f870c9cd",
   "metadata": {},
   "source": [
    "Los siguientes gráficos muestran la cantidad de tweets a lo largo del tiempo y los tweets por cada dias después del desastre:\n",
    "\n",
    "<center>\n",
    "<table style=\"border-collapse:collapse\"><tr>\n",
    "<td>\n",
    "<div>\n",
    "    <img src=\"images/tweets_tiempo.png\" width=\"400\"/>\n",
    "    <figcaption>Fig d.5 - tweets en el tiempo</figcaption>\n",
    "</div>\n",
    "</td>\n",
    "<td>\n",
    "<div>\n",
    "    <img src=\"images/tdd.png\" width=\"400\"/>\n",
    "    <figcaption>Fig d.6 - Cantidad de tweets por dia luego del desastre</figcaption>\n",
    "</div>\n",
    "</td>\n",
    "</tr></table>\n",
    "</center>\n",
    "\n",
    "Durante el análisis, se descubrió que al fusionar los conjuntos de datos del archivo JSON con el archivo TSV, quedaron tweets que no tenían etiquetado. Por lo tanto, se decidió tener un dataframe que contenga únicamente los tweets que están etiquetados según la columna \"text_human\" (para ciertas visualizaciones) y otro dataframe que incluya todos los tweets mencionados. La cantidad final de tweets quedó de la siguiente manera:\n",
    "\n",
    "<style>\n",
    "  .list-columns {\n",
    "    display: flex;\n",
    "    flex-wrap: wrap;\n",
    "    justify-content: space-between;\n",
    "    align-items: flex-start;\n",
    "    list-style: none;\n",
    "    padding: 0;\n",
    "    margin: 0;\n",
    "  }\n",
    "\n",
    "  .list-columns li {\n",
    "    width: calc(33.33% - 10px);\n",
    "    margin-bottom: 20px;\n",
    "  }\n",
    "</style>\n",
    "\n",
    "Cantidad de tweets con valores NaN en la columna \"text_human\":\n",
    "<ul class=\"list-columns\">\n",
    "  <li>California Wildfires: 1486 tweets</li>\n",
    "  <li>Hurricane Harvey: 3992 tweets</li>\n",
    "  <li>Hurricane Irma: 4018 tweets</li>\n",
    "  <li>Hurricane Maria: 3995 tweets</li>\n",
    "  <li>Iraq Iran Earthquake: 496 tweets</li>\n",
    "  <li>Mexico Earthquake: 1237 tweets</li>\n",
    "  <li>Srilanka Floods: 830 tweets</li>\n",
    "</ul>\n",
    "\n",
    "Cantidad de tweets sin valores NaN en la columna \"text_human\":\n",
    "<ul class=\"list-columns\">\n",
    "  <li>California Wildfires: 1370 tweets</li>\n",
    "  <li>Hurricane Harvey: 3315 tweets</li>\n",
    "  <li>Hurricane Irma: 3407 tweets</li>\n",
    "  <li>Hurricane Maria: 3537 tweets</li>\n",
    "  <li>Iraq Iran Earthquake: 452 tweets</li>\n",
    "  <li>Mexico Earthquake: 1067 tweets</li>\n",
    "  <li>Srilanka Floods: 751 tweets</li>\n",
    "</ul>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c767c0d0",
   "metadata": {},
   "source": [
    "### Preguntas y problemas"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4811e5db",
   "metadata": {},
   "source": [
    "<div class=text-justify>\n",
    "Habiendo terminado la exploración del dataset se plantean las siguientes preguntas y ademas del feedback, se deciden tratar de responder las siguientes preguntas para el ultimo hito:\n",
    "\n",
    "* ¿Qué tipos de tweets se encuentran en el dataset, sin contar las etiquetas que contemplan?\n",
    "* ¿Podemos determinar el tema humanitario del contenido de los tweets en base a las palabras utilizadas en este?\n",
    "\n",
    "Para responder a estas pregutas se realizara un analisis del texto de los tweets ademas de un preprosesamiento del mismo mediante el uso de tecnicas de NLP, como por ejemplo, la eliminacion de stopwords, creacion de embeddings usando un modelo preentrenado glove.\n",
    "</div>\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2129c3fb",
   "metadata": {},
   "source": [
    "### Propuesta experimental"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6c756e50",
   "metadata": {},
   "source": [
    "#### **¿Qué tipos de tweets se encuentran en el dataset, sin contar las etiquetas que contemplan?**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "92c0bbd5",
   "metadata": {},
   "source": [
    "Aquí se trató de responder a la primera pregunta, se hizo uso del dataframe con valores NaN en text_human, ya que contiene toda la información del dataset. Para esto se realizó un análisis de texto de los tweets, se hizo uso de tecnicas de NLP para poder obtener una mejor representacion de los tweets y asi poder clasificarlos en diferentes categorías. Luego se realizó un entrenamiento [inserte cantidad de modelos que usamos] para hacer clustering de los tweets y asi poder encontrar diferentes categorías de tweets aún no contempladas y ver como los tweets se agrupan en estas. \n",
    "\n",
    "Para eso, se hizo uso de un modelo preentrenado de glove, el cual es un modelo de embeddings que permite representar las palabras en un espacio vectorial de 300 dimensiones. Este modelo fue entrenado con un corpus de 6 billones de palabras, buscando garantizar que las palabras encontradas en el dataset estuvieran representadas en el modelo. Por otro lado, se hizo una limpieza del texto de los tweets, se eliminaron las stopwords y se eliminaron los carácteres especiales para hacer uso del modelo preentrenado y crear los embeddings de los tweets.\n",
    "\n",
    "La lista de las siguientes palabras se consideraron como stopwords debido a que no aportan información relevante al análisis de los tweets, se repiten mucho y pueden afectar los resultados. Por esto se decidió eliminarlas del texto de los tweets:\n",
    "\n",
    "```python\n",
    "additional_stop_words = ['california','californias', 'wildfires', 'hurricane', 'harvey', 'irma', 'maria', 'iraq', \n",
    "     'iran', 'earthquake', 'mexico', 'srilanka', 'floods','puerto','rico','us','texas','florida','texas','hurricanemaria',\n",
    "     'hurricaneharvey','puertorico','mexicoearthquake','houston','wildfire','ricos','tornado' , 'storm','flood','fire','trump',\n",
    "     'hurricanes','caribbean','flooding','disaster','irmas','tropical','harveys','st',\"mora\",'californiawildfires']\n",
    "```\n",
    "Luego de crear los embeddings de los tweets se hicieron los siguientes experimentos, los cuales hacen uso de diferentes modelos de clustering:\n",
    "- K-Means\n",
    "- DBSCAN\n",
    "- Anglomerative clustering\n",
    "\n",
    "\n",
    "\n",
    "<!--\n",
    "<center>\n",
    "<table><tr>\n",
    "<td>\n",
    "<div>\n",
    "    <img src=\"images/codo.png\" width=\"400\"/>\n",
    "    <figcaption>Fig d.7 - Gráfico del metodo del codo</figcaption>\n",
    "</div>\n",
    "</td>\n",
    "<td>\n",
    "<div>\n",
    "    <img src=\"images/kmeans.png\" width=\"400\"/>\n",
    "    <figcaption>Fig d.8 - Gráfico de los clusters</figcaption>\n",
    "</div>\n",
    "</td>\n",
    "</tr></table>\n",
    "</center>\n",
    "\n",
    "\n",
    "<center>\n",
    "<table>\n",
    "  <tr>\n",
    "    <th>favorite_count</th>\n",
    "    <th>retweet_count</th>\n",
    "    <th>reply_count</th>\n",
    "    <th>quote_count</th>\n",
    "    <th>tdd</th>\n",
    "    <th>magnitud</th>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>15.944902</td>\n",
    "    <td>8.721068</td>\n",
    "    <td>0.915700</td>\n",
    "    <td>1.413947</td>\n",
    "    <td>12.572835</td>\n",
    "    <td>0.060678</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>45792.666667</td>\n",
    "    <td>22862.333333</td>\n",
    "    <td>1807.000000</td>\n",
    "    <td>1157.666667</td>\n",
    "    <td>4.666667</td>\n",
    "    <td>0.055333</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>15875.363636</td>\n",
    "    <td>6813.272727</td>\n",
    "    <td>360.909091</td>\n",
    "    <td>1082.363636</td>\n",
    "    <td>3.545455</td>\n",
    "    <td>0.058727</td>\n",
    "  </tr>\n",
    "</table>\n",
    "</center>\n",
    "Basándonos en los grupos obtenidos, podemos inferir lo siguiente:\n",
    "\n",
    "- Grupo 1: Este grupo está compuesto por tweets que parecen no tener mucha relevancia o interacciones significativas. Estos tweets suelen ser más antiguos o estar más alejados en el tiempo del desastre.\n",
    "\n",
    "- Grupo 2: En este grupo se encuentran los tweets que han sido altamente virales, con una gran cantidad de interacciones. Estos tweets suelen tener fechas cercanas al desastre y han generado un mayor impacto en las redes sociales.\n",
    "\n",
    "- Grupo 3: Los tweets en este grupo muestran ciertas interacciones, pero no alcanzan el nivel de viralidad del Grupo 2. También se caracterizan por tener fechas cercanas al desastre.\n",
    "\n",
    "Además, se calculó el Silhouette Score y se obtuvo un valor de 0.996, lo cual indica que los clusters están bien definidos y separados entre sí.<br/>\n",
    "Como conclusiones preliminares, se puede deducir que las características de un tweet no tienen una relación aparente con la magnitud del desastre. Aunque se observan diferencias en la viralidad y la cercanía temporal al desastre, los grupos de clustering no muestran una magnitud claramente relacionada con estas características. Para el próximo hito, se plantea la posibilidad de calcular la magnitud del desastre utilizando datos externos y aplicar la misma metodología descrita para obtener una evaluación más precisa\n",
    "-->"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f78f1c92",
   "metadata": {},
   "source": [
    "### Resultados obtenidos\n",
    "\n",
    "#### K-Means\n",
    "\n",
    "En primer lugar, se utilizó el método del codo para obtener el siguiente gráfico, el cual nos permite determinar el número óptimo de clusters para el modelo de K-Means.\n",
    "\n",
    "<center>\n",
    "<div>\n",
    "    <img src=\"images/Codo_Hito3.png\" width=\"400\"/>\n",
    "    <figcaption>Fig d.7 - Gráfico método del codo</figcaption>\n",
    "</div>\n",
    "</center>\n",
    "\n",
    "A continuación se muestra el gráfico con los clusters obtenidos después de seleccionar el número óptimo de clusters igual a 4, identificado en el punto donde se produce el \"codo\" en el gráfico.\n",
    "\n",
    "\n",
    "<center>\n",
    "<div>\n",
    "    <img src=\"images/Kmenas_Hito3.png\" width=\"400\"/>\n",
    "    <figcaption>Fig d.8 - Gráfico de clusters Kmeans</figcaption>\n",
    "</div>\n",
    "</center>\n",
    "\n",
    "Además, se calcularon los siguientes valores de Silhouette Score para la cantidad de clusters:\n",
    "\n",
    "<center>\n",
    "\n",
    " ```Silhouette_score:  0.03347529043974475```\n",
    "</center>\n",
    "\n",
    "#### DBSCAN\n",
    "\n",
    "Se realiza un grafico para buscar el _eps_ optimo mediante el metodo de la rodilla, el cual nos permite encontrar el valor de _eps_ optimo para el modelo de DBSCAN.\n",
    "\n",
    "\n",
    "\n",
    "<center>\n",
    "<div>\n",
    "    <img src=\"images/rodilla.png\" width=\"400\"/>\n",
    "    <figcaption>Fig d.9 - Gráfico del método rodilla</figcaption>\n",
    "</div>\n",
    "</center>\n",
    "\n",
    "Se selecciona el valor de _eps_ igual a *1.77*, ya que es el punto donde se produce la curva más pronunciada en el gráfico. A continuación, se muestra el resultado con los clusters obtenidos.\n",
    "\n",
    "<center>\n",
    "<div>\n",
    "    <img src=\"images/dbscan_eps.png\" width=\"400\"/>\n",
    "    <figcaption>Fig d.10 - Gráfico de los clusters con la variable eps y el valor de min_sample fijo</figcaption>\n",
    "</div>\n",
    "</center>\n",
    "\n",
    "<center>\n",
    "<div>\n",
    "    <img src=\"images/dbscan_mn_samples.png\" width=\"400\"/>\n",
    "    <figcaption>Fig d.11 - Gráficos de los clusters con la variable min_sample y el valor de eps fijo.</figcaption>\n",
    "</div>\n",
    "</center>\n",
    "\n",
    "\n",
    "<center>\n",
    "<div>\n",
    "    <img src=\"images/dbscan_cluster.png\" width=\"400\"/>\n",
    "    <figcaption>Fig d.12 - Gráfico DBSCAN con eps y min_samples optimo</figcaption>\n",
    "</div>\n",
    "</center>\n",
    "\n",
    "Ademas se obtuvieron los siguientes silhouette score para cada cluster:\n",
    "<center>\n",
    "\n",
    "```silhouette_score : 0.13940395380808834```\n",
    "\n",
    "\n",
    "</center>\n",
    "\n",
    "Se puede observar que este método no ofrece un silhouette score muy alto y visualmente no se pueden distinguir grupos claramente definidos. Además, al realizar la clasificación de los tweets, se encontró que la mayoría de ellos pertenecen al cluster 0, mientras que los demás clusters están menos poblados.\n",
    "<center>\n",
    "\n",
    "```\n",
    "cluster 0:   12223\n",
    "cluster 1:  4\n",
    "cluster 2:  4\n",
    "cluster 3:  150\n",
    "```\n",
    "\n",
    "</center>\n",
    "\n",
    "#### Agglomerative clustering\n",
    "\n",
    "Se realiza un gráfico de dendograma para encontrar el número de clusters óptimo para el modelo de Agglomerative clustering.\n",
    "\n",
    "<center>\n",
    "<div>\n",
    "    <img src=\"images/Dendograma_Hito3.png\" width=\"400\"/>\n",
    "    <figcaption>Fig d.13 - Gráfico dendograma</figcaption>\n",
    "</div>\n",
    "</center>\n",
    "\n",
    "Se selecciona la altura 1, obteniendo un número de clusters igual a 5. Luego se obtiene el resultado de silhoutte score:\n",
    "\n",
    "<center>\n",
    "\n",
    "```silhouette_score : 0.005792798577369514```\n",
    "</center>\n",
    "Finalmente, el modelo de K-Means fue el que obtuvo el mejor resultado, a pesar de obtener un silhoutte score de 0.03. Por otro lado, el modelo DBSCAN obtuvo un mejor score, pero su distribución fue mucho peor, por lo que no se considera válido.\n",
    "\n",
    "Al revisar manualmente 20 tweets de cada cluster separados por K-Means, no se encontró una temática que justificara la agrupación. Los clusters no mostraban una relación clara entre sí y no se diferenciaban significativamente.\n",
    "\n",
    "En general, ninguno de los modelos obtuvo un silhoutte score muy alto, lo cual indica que los clusters no están bien definidos. Esto se debe a que los tweets no están claramente separados entre sí, ya que muchos de ellos comparten las mismas palabras. Por lo tanto, <u>**no es posible encontrar una forma clara de agrupar los tweets**</u>.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7c718d1a",
   "metadata": {},
   "source": [
    "#### **¿Podemos determinar el tema humanitario de contenido de los tweets en base a las palabras utilizadas en este?**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "692f1682",
   "metadata": {},
   "source": [
    "\n",
    "Para responder a esta pregunta, se requiere realizar un análisis del texto de los tweets utilizando técnicas de procesamiento de lenguaje natural (NLP).<br/>\n",
    "\n",
    "Se decidió utilizar clasificación, entrenando distintos modelos sobre los textos de los tweets. En primer lugar, se realizó un estudio sobre embeddings de palabras y como utilizarlos para mejorar el desempeño de la clasificación. Estos embeddings son medidas numéricas que buscan contextualizar las palabras, considerando que aquellas palabras que tienen un mismo significado representan contextos similares en un tweet.\n",
    "Inicialmente, se planteó la utilización de la técnica Word2Vec para realizar el embedding del texto de los tweets. Sin embargo, este método se entrena utilizando los mismos textos de los tweets para aprender el contexto de las palabras, y no se tiene la cantidad suficiente de información para generar embeddings aceptables. Por lo tanto, se decidió cambiar al modelo GloVe, el cual cuenta con vectores preprocesados para una gran cantidad de palabras del vocabulario, donde para cada palabra existe un vector de largo 200 con los valores que la representan en el texto. Esto mejoró los resultados y la velocidad de procesamiento. Además, se utilizaron las palabras más frecuentes del dataset (en este caso, los nombres de los desastres y sus ubicaciones) como stopwords durante el preprocesamiento y que este aspecto no influyera para el entrenamiento del clasificador.<br/>\n",
    "Se separaron los conjuntos de entrenamiento y prueba en un 80\\% y 20\\% de los datos, respectivamente. Posteriormente, se generaron los vectores y los textos de entrenamiento y prueba. Finalmente, se calculó el promedio de la representación vectorial de cada palabra en un tweet.<br/>\n",
    "Con todo este procesamiento, se probaron diferentes clasificadores y se compararon sus resultados. Para esto se trabajó con los siguientes modelos:<br/>\n",
    "<center>\n",
    "<div style=\"display: flex; flex-wrap: wrap; justify-content: space-between;\">\n",
    "  <div style=\"width: 25%;\">\n",
    "    <strong>LinearSVC</strong>\n",
    "  </div>\n",
    "  <div style=\"width: 25%;\">\n",
    "    <strong>DecisionTreeClassifier</strong>\n",
    "  </div>\n",
    "  <div style=\"width: 25%;\">\n",
    "    <strong>RandomForestClassifier</strong>\n",
    "  </div>\n",
    "  <div style=\"width: 25%;\">\n",
    "    <strong>NaiveBayes</strong>\n",
    "  </div>\n",
    "</div>\n",
    "</center>\n",
    "\n",
    "El objetivo fue entrenar un clasificador que fuera capaz de distinguir entre los distintos tipos de información humanitaria presente en los tweets. Las categorías que componen la columna \"text_human\" corresponden a: missing_or_found_people, vehicle_damage, affected_individuals, injured_or_dead_people, infrastructure_and_utility_damage, rescue_volunteering_or_donation_effort, not_humanitarian y other_relevant_information. Se consideraró realizar un rebalanceo de las clases, ya que las primeras 4 mencionadas presentan una frecuencia considerablemente menor que las demás. Se propuso agrupar estas 4 etiquetas en una nueva para mitigar este desequilibrio. Esta nueva etiqueta se denominó \"human_and_material_losses\". <br/>\n",
    "Para evaluar la efectividad de los clasificadores, se utilizaron las métricas de exactitud (accuracy), la precisión (precision), la recuperación (recall) y la puntuación F1 (F1 score)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa29c6c2",
   "metadata": {},
   "source": [
    "<center>\n",
    "<table>\n",
    "  <tr>\n",
    "    <th>Modelo</th>\n",
    "    <th>Accuracy</th>\n",
    "    <th>Precision</th>\n",
    "    <th>Recall</th>\n",
    "    <th>F1 Score</th>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>Linear SVC</td>\n",
    "    <td>0.628</td>\n",
    "    <td>0.635</td>\n",
    "    <td>0.612</td>\n",
    "    <td>0.619</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>Decision tree</td>\n",
    "    <td>0.422</td>\n",
    "    <td>0.402</td>\n",
    "    <td>0.401</td>\n",
    "    <td>0.402</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>Random Forest</td>\n",
    "    <td>0.586</td>\n",
    "    <td>0.637</td>\n",
    "    <td>0.533</td>\n",
    "    <td>0.548</td>\n",
    "  </tr>\n",
    "   <tr>\n",
    "    <td>Naive Bayes Gaussian</td>\n",
    "    <td>0.596</td>\n",
    "    <td>0.587</td>\n",
    "    <td>0.602</td>\n",
    "    <td>0.593</td>\n",
    "  </tr>\n",
    "</table>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a633235c",
   "metadata": {},
   "source": [
    "Se puede ver que el clasificador con mejores resultados es LinearSVC, para este se incluye además un heatmap que muestra su desempeño con las clases.\n",
    "\n",
    "<center>\n",
    "<div>\n",
    "    <img src=\"images/heatmap_linearSVC_quadclass.png\" width=\"500\"/>\n",
    "    <figcaption>Fig d.14 - Heatmap para LinearSVC con 4 clases</figcaption>\n",
    "</div>\n",
    "</center>\n",
    "\n",
    "El heatmap muestra como el clasificador tiene problemas con la categoría other_relevant_information al comparla con human_and_material_losses y not_humanitarian. Esto es razonable ya que other_relevant_information es un concepto muy amplio el cual no es claramente diferenciable de estas dos categorias, tomando en cuenta que human_and_material_losses ya es una agregación de varias categorías las cuales acumulan una cantidad menor de tweets en comparación al resto y not_humanitarian tiene aspectos no contexualizables o no relevantes para el tema de desastres y por esto es más difícil encontrar una relación que las diferencie. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cc80916",
   "metadata": {},
   "source": [
    "También se hizo un experimento utilizando el mejor clasificador (LinearSVC) quitando los tweets de categoría not_humanitarian, de esta forma el clasificador sólo trabajó sobre un conjunto de tweets con información humanitaria. Sus resultados fueron mejores que antes:\n",
    "\n",
    "- Accuracy: 0.743\n",
    "- Decision tree: 0.728\n",
    "- Random Forest: 0.694\n",
    "- Naive Bayes Gaussian: 0.698\n",
    "\n",
    "Los resultados probablemente se deban a la forma en que el clasificador confunde a menudo la categoría not_humanitarian con other_relevant_information, como se muestra en el heatmap anterior. Por lo tanto, al remover estos tweets el clasificador aprende de mejor forma las diferencias que hay entre cada tema humanitario.\n",
    "Sin embargo, se puede apreciar que el problema entre human_and_material_losses y other_relevant_information aún persiste (nuevamente, por lo descrito anteriormente).\n",
    "\n",
    "<center>\n",
    "<div>\n",
    "    <img src=\"images/heatmap_linearSVC_triclass.png\" width=\"500\"/>\n",
    "    <figcaption>Fig d.15 - Heatmap para LinearSVC con 3 clases</figcaption>\n",
    "</div>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d69db50a",
   "metadata": {},
   "source": [
    "Los resultados nos muestran que es posible crear un clasificador que entregue buenas métricas de desempeño aún teniendo en cuenta el desbalanceo de las clases o los aspectos internos de los datos que compliquen el diferenciar una clase de otra. Se espera que, en el caso de tener una mayor cantidad de datos a disposición que permitan balancear las clases, estos resultados sean mejores."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fda9e429",
   "metadata": {},
   "source": [
    "## Conclusiones"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a488fd8b",
   "metadata": {},
   "source": [
    "El trabajo realizado durante este proyecto aportó conocimientos interesantes sobre el análisis de datos públicos, en este caso, como publicaciones de una red social y como estos pueden ser categorizados utilizando las herramientas aprendidas durante el semestre para generar un estudio de las interacciones de las personas."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8faea7b4",
   "metadata": {},
   "source": [
    "## Aportes\n",
    "Para este Hito se realizaron las siguientes contribuciones.\n",
    "\n",
    "* Códigos de clustering: Stevens y Jorge\n",
    "* Codigos de clasificación: Jessica, Agustín y Jesús\n",
    "* Redacción Metodologia y resultados pregunta: Stevens y Jorge\n",
    "* Redacción Metodologia y resultados segunda pregunta: Jessica y Jesús\n",
    "* Presentación: Jessica \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "06fdacb2",
   "metadata": {},
   "source": [
    "## Anexo\n",
    "Los códigos se encuentran en la carpeta \"/codigo\", especificamente en el archivo \"codigo_entrega2.ipynb\". Las imágenes utilizadas en este html se encuentran en la carpeta \"/images\"."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
