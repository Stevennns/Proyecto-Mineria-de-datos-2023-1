{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports y funciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\steve\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "import regex as re\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_hashtags_text(x):\n",
    "    if pd.notna(x) and 'hashtags' in x and x['hashtags']:\n",
    "        hashtags = x['hashtags']\n",
    "        hashtags_text = [ht['text'] for ht in hashtags]\n",
    "        return hashtags_text\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "def get_urls(x):\n",
    "    if pd.notna(x) and 'urls' in x and x['urls']:\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "\n",
    "def get_user_location(x):\n",
    "    if pd.notna(x) and 'location' in x:\n",
    "        return x['location']\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "\n",
    "def load_json(file_path):\n",
    "    df_new = pd.DataFrame()\n",
    "\n",
    "    try:\n",
    "        # Leer el archivo JSON línea por línea y cargar los datos en una lista\n",
    "        datos_json = []\n",
    "        with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "            for line in f:\n",
    "                data = json.loads(line)\n",
    "                if 'retweeted_status' in data and data['retweeted_status'] != None:\n",
    "                    data = data['retweeted_status']\n",
    "                datos_json.append(data)\n",
    "\n",
    "        df = pd.DataFrame(datos_json)\n",
    "\n",
    "        df_new['id'] = df['id']\n",
    "        df_new['lang'] = df['lang']\n",
    "        df_new['text'] = df['text']\n",
    "        df_new['favorite_count'] = df['favorite_count']\n",
    "        df_new['retweet_count'] = df['retweet_count']\n",
    "        df_new['possibly_sensitive'] = df['possibly_sensitive']\n",
    "        df_new['created_at'] = df['created_at']\n",
    "        df_new['is_quote_status'] = df['is_quote_status']\n",
    "        df_new['entities_hashtags_text'] = df['entities'].apply(get_hashtags_text)\n",
    "        df_new['entities_urls'] = df['entities'].apply(get_urls)\n",
    "        df_new['user_location'] = df['user'].apply(get_user_location)\n",
    "        \n",
    "        # Asignar 0 a las columnas 'reply_count' y 'quote_count' si no existen\n",
    "        df_new['reply_count'] = df.get('reply_count', 0)\n",
    "        df_new['quote_count'] = df.get('quote_count', 0)\n",
    "\n",
    "        # Verificar si hay al menos una imagen en el JSON\n",
    "        has_image = []\n",
    "        for i in range(len(df)):\n",
    "            try:\n",
    "                extended_entities = df['extended_entities'][i]\n",
    "                if 'media' in extended_entities and len(extended_entities['media']) > 0:\n",
    "                    has_image.append(True)\n",
    "                else:\n",
    "                    has_image.append(False)\n",
    "            except (KeyError, TypeError):\n",
    "                has_image.append(False)\n",
    "\n",
    "        df_new['has_image'] = has_image\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f'Se produjo una excepción: {e}')\n",
    "\n",
    "    # Retornar el DataFrame resultante\n",
    "    return df_new\n",
    "\n",
    "def get_magnitud(df):\n",
    "    #print(mexico.shape)\n",
    "    weights = [0.2,0.2,0.3,0.05,0,0.05,0.05,0.15]\n",
    "\n",
    "    human= pd.DataFrame(data=np.zeros(8),\n",
    "                        columns=[\"proportion\"],\n",
    "                        index=[\"affected_individuals\",\n",
    "                                \"infrastructure_and_utility_damage\",\n",
    "                                \"injured_or_dead_people\",\n",
    "                                \"missing_or_found_people\",\n",
    "                                \"not_humanitarian\",\n",
    "                                \"other_relevant_information\",\n",
    "                                \"rescue_volunteering_or_donation_effort\",\n",
    "                                \"vehicle_damage\"]\n",
    "                        )\n",
    "\n",
    "    #print(human)\n",
    "    a = df[\"text_human\"].value_counts(normalize=True)\n",
    "    a = a.to_frame().add(human,fill_value=0)\n",
    "\n",
    "    #print(a)\n",
    "\n",
    "    return round(np.average(a=a[\"proportion\"],weights=weights),3)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Magnitud Mexico"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.073\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>lang</th>\n",
       "      <th>text</th>\n",
       "      <th>favorite_count</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>possibly_sensitive</th>\n",
       "      <th>created_at</th>\n",
       "      <th>is_quote_status</th>\n",
       "      <th>entities_hashtags_text</th>\n",
       "      <th>entities_urls</th>\n",
       "      <th>user_location</th>\n",
       "      <th>reply_count</th>\n",
       "      <th>quote_count</th>\n",
       "      <th>has_image</th>\n",
       "      <th>text_info</th>\n",
       "      <th>text_info_conf</th>\n",
       "      <th>text_human</th>\n",
       "      <th>text_human_conf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>910523388598280192</td>\n",
       "      <td>en</td>\n",
       "      <td>Mexico earthquake: Many children killed at pri...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>Wed Sep 20 15:17:47 +0000 2017</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>india</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>informative</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>injured_or_dead_people</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>910523397448314882</td>\n",
       "      <td>en</td>\n",
       "      <td>Obama’s Response To The Earthquake In #MexicoC...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>Wed Sep 20 15:17:49 +0000 2017</td>\n",
       "      <td>False</td>\n",
       "      <td>[MexicoCity, President, SoundsLike]</td>\n",
       "      <td>True</td>\n",
       "      <td>None</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>not_informative</td>\n",
       "      <td>0.6643</td>\n",
       "      <td>not_humanitarian</td>\n",
       "      <td>0.6643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>910523407489470464</td>\n",
       "      <td>en</td>\n",
       "      <td>NEWS: At least 200 people, including 21 childr...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>Wed Sep 20 15:17:51 +0000 2017</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>Chester, UK</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>informative</td>\n",
       "      <td>0.6848</td>\n",
       "      <td>injured_or_dead_people</td>\n",
       "      <td>0.6848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>910523518827167744</td>\n",
       "      <td>en</td>\n",
       "      <td>At least 49 dead as strong 7.1 magnitude earth...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>Wed Sep 20 15:18:18 +0000 2017</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>Earth</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>informative</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>injured_or_dead_people</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>910523546442575873</td>\n",
       "      <td>en</td>\n",
       "      <td>Earthquake causes widespread damage around Mex...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>Wed Sep 20 15:18:24 +0000 2017</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>Gurgaon</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>informative</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>injured_or_dead_people</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1062</th>\n",
       "      <td>916105333872918528</td>\n",
       "      <td>en</td>\n",
       "      <td>Carlos santana donates $100k to mexico earthqu...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>Fri Oct 06 00:58:26 +0000 2017</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>CA FL MA NV OH WV</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>informative</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>rescue_volunteering_or_donation_effort</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1063</th>\n",
       "      <td>916105374134042624</td>\n",
       "      <td>en</td>\n",
       "      <td>Seth troxler donates 10k to earthquake relief ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>Fri Oct 06 00:58:36 +0000 2017</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>CA FL MA NV OH WV</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>informative</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>rescue_volunteering_or_donation_effort</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1064</th>\n",
       "      <td>916112796194021376</td>\n",
       "      <td>en</td>\n",
       "      <td>Entercom/San Francisco Stations Raise Funds Fo...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>Fri Oct 06 01:28:05 +0000 2017</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>America</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>informative</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>rescue_volunteering_or_donation_effort</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1065</th>\n",
       "      <td>916164076484653056</td>\n",
       "      <td>en</td>\n",
       "      <td>Mexico Earthquakes | International Medical Cor...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>Fri Oct 06 04:51:51 +0000 2017</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>USA Heartland, Second Life</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>informative</td>\n",
       "      <td>0.6580</td>\n",
       "      <td>other_relevant_information</td>\n",
       "      <td>0.6580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1066</th>\n",
       "      <td>916167674673156096</td>\n",
       "      <td>en</td>\n",
       "      <td>Napa school employee Valentin Fuentes Villanue...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>Fri Oct 06 05:06:09 +0000 2017</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>Napa, California</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>informative</td>\n",
       "      <td>0.5635</td>\n",
       "      <td>injured_or_dead_people</td>\n",
       "      <td>0.5635</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1067 rows × 18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      id lang   \n",
       "0     910523388598280192   en  \\\n",
       "1     910523397448314882   en   \n",
       "2     910523407489470464   en   \n",
       "3     910523518827167744   en   \n",
       "4     910523546442575873   en   \n",
       "...                  ...  ...   \n",
       "1062  916105333872918528   en   \n",
       "1063  916105374134042624   en   \n",
       "1064  916112796194021376   en   \n",
       "1065  916164076484653056   en   \n",
       "1066  916167674673156096   en   \n",
       "\n",
       "                                                   text  favorite_count   \n",
       "0     Mexico earthquake: Many children killed at pri...               0  \\\n",
       "1     Obama’s Response To The Earthquake In #MexicoC...               0   \n",
       "2     NEWS: At least 200 people, including 21 childr...               0   \n",
       "3     At least 49 dead as strong 7.1 magnitude earth...               0   \n",
       "4     Earthquake causes widespread damage around Mex...               0   \n",
       "...                                                 ...             ...   \n",
       "1062  Carlos santana donates $100k to mexico earthqu...               0   \n",
       "1063  Seth troxler donates 10k to earthquake relief ...               0   \n",
       "1064  Entercom/San Francisco Stations Raise Funds Fo...               0   \n",
       "1065  Mexico Earthquakes | International Medical Cor...               0   \n",
       "1066  Napa school employee Valentin Fuentes Villanue...               0   \n",
       "\n",
       "      retweet_count  possibly_sensitive                      created_at   \n",
       "0                 0               False  Wed Sep 20 15:17:47 +0000 2017  \\\n",
       "1                 0               False  Wed Sep 20 15:17:49 +0000 2017   \n",
       "2                 0               False  Wed Sep 20 15:17:51 +0000 2017   \n",
       "3                 0               False  Wed Sep 20 15:18:18 +0000 2017   \n",
       "4                 0               False  Wed Sep 20 15:18:24 +0000 2017   \n",
       "...             ...                 ...                             ...   \n",
       "1062              0               False  Fri Oct 06 00:58:26 +0000 2017   \n",
       "1063              0               False  Fri Oct 06 00:58:36 +0000 2017   \n",
       "1064              0               False  Fri Oct 06 01:28:05 +0000 2017   \n",
       "1065              0               False  Fri Oct 06 04:51:51 +0000 2017   \n",
       "1066              0               False  Fri Oct 06 05:06:09 +0000 2017   \n",
       "\n",
       "     is_quote_status               entities_hashtags_text  entities_urls   \n",
       "0              False                                 None           True  \\\n",
       "1              False  [MexicoCity, President, SoundsLike]           True   \n",
       "2              False                                 None          False   \n",
       "3              False                                 None           True   \n",
       "4              False                                 None           True   \n",
       "...              ...                                  ...            ...   \n",
       "1062           False                                 None           True   \n",
       "1063           False                                 None           True   \n",
       "1064           False                                 None           True   \n",
       "1065           False                                 None           True   \n",
       "1066           False                                 None           True   \n",
       "\n",
       "                   user_location  reply_count  quote_count  has_image   \n",
       "0                          india          0.0            0       True  \\\n",
       "1                           None          0.0            0       True   \n",
       "2                    Chester, UK          0.0            0       True   \n",
       "3                          Earth          0.0            0       True   \n",
       "4                        Gurgaon          0.0            0       True   \n",
       "...                          ...          ...          ...        ...   \n",
       "1062           CA FL MA NV OH WV          0.0            0       True   \n",
       "1063           CA FL MA NV OH WV          0.0            0       True   \n",
       "1064                     America          0.0            0       True   \n",
       "1065  USA Heartland, Second Life          0.0            0       True   \n",
       "1066            Napa, California          0.0            0       True   \n",
       "\n",
       "            text_info  text_info_conf                              text_human   \n",
       "0         informative          1.0000                  injured_or_dead_people  \\\n",
       "1     not_informative          0.6643                        not_humanitarian   \n",
       "2         informative          0.6848                  injured_or_dead_people   \n",
       "3         informative          1.0000                  injured_or_dead_people   \n",
       "4         informative          1.0000                  injured_or_dead_people   \n",
       "...               ...             ...                                     ...   \n",
       "1062      informative          1.0000  rescue_volunteering_or_donation_effort   \n",
       "1063      informative          1.0000  rescue_volunteering_or_donation_effort   \n",
       "1064      informative          1.0000  rescue_volunteering_or_donation_effort   \n",
       "1065      informative          0.6580              other_relevant_information   \n",
       "1066      informative          0.5635                  injured_or_dead_people   \n",
       "\n",
       "      text_human_conf  \n",
       "0              1.0000  \n",
       "1              0.6643  \n",
       "2              0.6848  \n",
       "3              1.0000  \n",
       "4              1.0000  \n",
       "...               ...  \n",
       "1062           1.0000  \n",
       "1063           1.0000  \n",
       "1064           1.0000  \n",
       "1065           0.6580  \n",
       "1066           0.5635  \n",
       "\n",
       "[1067 rows x 18 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mexico_json = load_json(\"RDATA/CrisisMMD_v2.0/json/mexico_earthquake_final_data.json\")\n",
    "mexico_tsv = pd.read_table(\"RDATA/CrisisMMD_v2.0/annotations/mexico_earthquake_final_data.tsv\")\n",
    "\n",
    "mexico = pd.merge(mexico_json, mexico_tsv[['tweet_id', 'text_info', 'text_info_conf', 'text_human', 'text_human_conf']],\n",
    "                    left_on='id', right_on='tweet_id', how='left')\n",
    "mexico.drop('tweet_id',axis=1,inplace=True)\n",
    "mexico =  mexico[mexico['text_human'].notna()]\n",
    "mexico = mexico.drop_duplicates(subset=['id']).reset_index(drop=True)\n",
    "magnitud = get_magnitud(mexico)\n",
    "print(magnitud)\n",
    "\n",
    "\n",
    "mexico[mexico[\"favorite_count\"]]\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Magnitud iraq Iran"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.107\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>lang</th>\n",
       "      <th>text</th>\n",
       "      <th>favorite_count</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>possibly_sensitive</th>\n",
       "      <th>created_at</th>\n",
       "      <th>is_quote_status</th>\n",
       "      <th>entities_hashtags_text</th>\n",
       "      <th>entities_urls</th>\n",
       "      <th>user_location</th>\n",
       "      <th>reply_count</th>\n",
       "      <th>quote_count</th>\n",
       "      <th>has_image</th>\n",
       "      <th>text_info</th>\n",
       "      <th>text_info_conf</th>\n",
       "      <th>text_human</th>\n",
       "      <th>text_human_conf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [id, lang, text, favorite_count, retweet_count, possibly_sensitive, created_at, is_quote_status, entities_hashtags_text, entities_urls, user_location, reply_count, quote_count, has_image, text_info, text_info_conf, text_human, text_human_conf]\n",
       "Index: []"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iraq_json = load_json(\"RDATA/CrisisMMD_v2.0/json/iraq_iran_earthquake_final_data.json\")\n",
    "iraq_tsv = pd.read_table(\"RDATA/CrisisMMD_v2.0/annotations/iraq_iran_earthquake_final_data.tsv\")\n",
    "\n",
    "iraq = pd.merge(iraq_json, iraq_tsv[['tweet_id', 'text_info', 'text_info_conf', 'text_human', 'text_human_conf']],\n",
    "                    left_on='id', right_on='tweet_id', how='left')\n",
    "iraq.drop('tweet_id',axis=1,inplace=True)\n",
    "iraq =  iraq[iraq['text_human'].notna()]\n",
    "iraq = iraq.drop_duplicates(subset=['id']).reset_index(drop=True)\n",
    "magnitud = get_magnitud(iraq)\n",
    "print(magnitud)\n",
    "\n",
    "\n",
    "iraq[iraq[\"favorite_count\"]>0]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Magnitud California"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.078\n"
     ]
    }
   ],
   "source": [
    "california_json = load_json(\"RDATA/CrisisMMD_v2.0/json/california_wildfires_final_data.json\")\n",
    "california_tsv = pd.read_table(\"RDATA/CrisisMMD_v2.0/annotations/california_wildfires_final_data.tsv\")\n",
    "\n",
    "california = pd.merge(california_json, california_tsv[['tweet_id', 'text_info', 'text_info_conf', 'text_human', 'text_human_conf']],\n",
    "                    left_on='id', right_on='tweet_id', how='left')\n",
    "california.drop('tweet_id',axis=1,inplace=True)\n",
    "california =  california[california['text_human'].notna()]\n",
    "california = california.drop_duplicates(subset=['id']).reset_index(drop=True)\n",
    "magnitud = get_magnitud(california)\n",
    "print(magnitud)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Magnitud Harvey"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.06\n"
     ]
    }
   ],
   "source": [
    "harvey_json = load_json(\"RDATA/CrisisMMD_v2.0/json/hurricane_harvey_final_data.json\")\n",
    "harvey_tsv = pd.read_table(\"RDATA/CrisisMMD_v2.0/annotations/hurricane_harvey_final_data.tsv\")\n",
    "\n",
    "harvey = pd.merge(harvey_json, harvey_tsv[['tweet_id', 'text_info', 'text_info_conf', 'text_human', 'text_human_conf']],\n",
    "                    left_on='id', right_on='tweet_id', how='left')\n",
    "harvey.drop('tweet_id',axis=1,inplace=True)\n",
    "harvey =  harvey[harvey['text_human'].notna()]\n",
    "harvey = harvey.drop_duplicates(subset=['id']).reset_index(drop=True)\n",
    "magnitud = get_magnitud(harvey)\n",
    "print(magnitud)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Magnitud Irma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.06\n"
     ]
    }
   ],
   "source": [
    "irma_json = load_json(\"RDATA/CrisisMMD_v2.0/json/hurricane_irma_final_data.json\")\n",
    "irma_tsv = pd.read_table(\"RDATA/CrisisMMD_v2.0/annotations/hurricane_irma_final_data.tsv\")\n",
    "\n",
    "irma = pd.merge(irma_json, irma_tsv[['tweet_id', 'text_info', 'text_info_conf', 'text_human', 'text_human_conf']],\n",
    "                    left_on='id', right_on='tweet_id', how='left')\n",
    "irma.drop('tweet_id',axis=1,inplace=True)\n",
    "irma =  irma[irma['text_human'].notna()]\n",
    "irma = irma.drop_duplicates(subset=['id']).reset_index(drop=True)\n",
    "magnitud = get_magnitud(irma)\n",
    "print(magnitud)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Magnitud Maria"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.046\n"
     ]
    }
   ],
   "source": [
    "maria_json = load_json(\"RDATA/CrisisMMD_v2.0/json/hurricane_maria_final_data.json\")\n",
    "maria_tsv = pd.read_table(\"RDATA/CrisisMMD_v2.0/annotations/hurricane_maria_final_data.tsv\")\n",
    "\n",
    "maria = pd.merge(maria_json, maria_tsv[['tweet_id', 'text_info', 'text_info_conf', 'text_human', 'text_human_conf']],\n",
    "                    left_on='id', right_on='tweet_id', how='left')\n",
    "maria.drop('tweet_id',axis=1,inplace=True)\n",
    "maria =  maria[maria['text_human'].notna()]\n",
    "maria = maria.drop_duplicates(subset=['id']).reset_index(drop=True)\n",
    "magnitud = get_magnitud(maria)\n",
    "print(magnitud)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Magnitud Srilanka"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.03\n"
     ]
    }
   ],
   "source": [
    "srilanka_json = load_json(\"RDATA/CrisisMMD_v2.0/json/srilanka_floods_final_data.json\")\n",
    "srilanka_tsv = pd.read_table(\"RDATA/CrisisMMD_v2.0/annotations/srilanka_floods_final_data.tsv\")\n",
    "\n",
    "srilanka = pd.merge(srilanka_json, srilanka_tsv[['tweet_id', 'text_info', 'text_info_conf', 'text_human', 'text_human_conf']],\n",
    "                    left_on='id', right_on='tweet_id', how='left')\n",
    "srilanka.drop('tweet_id',axis=1,inplace=True)\n",
    "srilanka =  srilanka[srilanka['text_human'].notna()]\n",
    "srilanka = srilanka.drop_duplicates(subset=['id']).reset_index(drop=True)\n",
    "magnitud = get_magnitud(srilanka)\n",
    "print(magnitud)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
