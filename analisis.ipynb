{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Limpieza de los datos (HITO 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "# Ruta del archivo JSON\n",
    "ruta_archivo = \"RDATA/CrisisMMD_v2.0/json/mexico_earthquake_final_data.json\"\n",
    "\n",
    "# Leer el archivo JSON línea por línea y cargar los datos en una lista\n",
    "datos_json = []\n",
    "with open(ruta_archivo, \"r\", encoding=\"utf-8\") as f:\n",
    "    for line in f:\n",
    "        data = json.loads(line)\n",
    "        datos_json.append(data)\n",
    "\n",
    "# Convertir la lista de datos en un DataFrame de Pandas\n",
    "df = pd.DataFrame(datos_json)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtrar el DataFrame por el ID específico usando indexación booleana\n",
    "df_resultado = df[df['id'] == 910512243640545280]\n",
    "\n",
    "# Mostrar el resultado\n",
    "print(df_resultado)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mostrar los nombres de las columnas del DataFrame\n",
    "print(df.columns)\n",
    "(df['entities'])['hashtags']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En caso de ser un retweeted_status, extraer la info del json anidado.\n",
    "- quote_count\n",
    "- possibly_sensitive\n",
    "- lang\n",
    "- id\n",
    "- created_at\n",
    "- favorite_count\n",
    "- text\n",
    "- reply_count\n",
    "- entities:hashtags:(text solamente)\n",
    "- entities:urls: booleano si hay almenos 1\n",
    "- is_quote_status (buscar un true)\n",
    "- retweet_count\n",
    "- user: Location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Contar la cantidad de filas que cumplen condicion'\n",
    "columna = 'is_quote_status'\n",
    "nulos = (df[f'{columna}']==True).sum()\n",
    "\n",
    "# Calcular el total de filas en el DataFrame\n",
    "total_filas = len(df)\n",
    "\n",
    "# Calcular el porcentaje de filas con nulos en 'quote_count'\n",
    "porcentaje = (nulos / total_filas) * 100\n",
    "\n",
    "# Mostrar los resultados\n",
    "print(f\"Cantidad de filas con nulos en {columna}:\", nulos)\n",
    "print(\"Total de filas en el DataFrame:\", total_filas)\n",
    "print(f\"Porcentaje de filas que cumplen la condicion de '{columna}':\", porcentaje, \"%\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funciones para extraer la información de los JSON\n",
    "\n",
    "# Definir la función para obtener el texto de los hashtags\n",
    "def get_hashtags_text(x):\n",
    "    if pd.notna(x) and 'hashtags' in x and x['hashtags']:\n",
    "        hashtags = x['hashtags']\n",
    "        hashtags_text = [ht['text'] for ht in hashtags]\n",
    "        return hashtags_text\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "def get_urls(x):\n",
    "    if pd.notna(x) and 'urls' in x and x['urls']:\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "\n",
    "def get_user_location(x):\n",
    "    if pd.notna(x) and 'location' in x:\n",
    "        return x['location']\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "# Extraer las columnas solicitadas en un nuevo DataFrame\n",
    "df_new = df[['quote_count', 'possibly_sensitive', 'lang', 'id', 'created_at',\n",
    "             'favorite_count', 'text', 'reply_count', 'entities', 'is_quote_status',\n",
    "             'retweet_count', 'user']]\n",
    "\n",
    "# Extraer la información de los JSON y agregarla como nuevas columnas\n",
    "df_new['entities_hashtags_text'] = df['entities'].apply(get_hashtags_text)\n",
    "df_new['entities_urls'] = df['entities'].apply(get_urls)\n",
    "df_new['user_location'] = df['user'].apply(get_user_location)\n",
    "\n",
    "# Mostrar el nuevo DataFrame\n",
    "df_new\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear un nuevo DataFrame con las columnas deseadas\n",
    "df_new2 = df[['id','lang','text','favorite_count','quote_count','reply_count','retweet_count', 'possibly_sensitive','created_at',\n",
    "                'entities', 'is_quote_status',\n",
    "              'user']]\n",
    "\n",
    "# Filtrar las filas donde \"retweeted_status\" no sea None o NaN\n",
    "df_new2 = df_new2[df['retweeted_status'].isna()]\n",
    "\n",
    "# Extraer la información de los hashtags, URLs y ubicación de usuario y agregarla como nuevas columnas\n",
    "df_new2['entities_hashtags_text'] = df_new2['entities'].apply(get_hashtags_text).apply(lambda x: x if x else None)\n",
    "df_new2['entities_urls'] = df_new2['entities'].apply(get_urls)\n",
    "df_new2['user_location'] = df_new2['user'].apply(get_user_location)\n",
    "\n",
    "# Eliminar las columnas \"user\" y \"entities\"\n",
    "df_new2.drop(['user', 'entities'], axis=1, inplace=True)\n",
    "\n",
    "# Mostrar el DataFrame resultante\n",
    "df_resultado = df_new2[df_new2['id'] == 916164076484653056]\n",
    "(df_new2[f'{columna}']==True).sum()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-text_info\n",
    "-text_info_conf\n",
    "-text_human\n",
    "-text_human_conf\t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read TSV file into DataFrame\n",
    "df2 = pd.read_table('RDATA/CrisisMMD_v2.0/annotations/mexico_earthquake_final_data.tsv')\n",
    "a =df2['']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(df2['tweet_id'] == 910524110828171264).any()\n",
    "df.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
